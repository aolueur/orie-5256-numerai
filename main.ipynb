{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-MR1gga_hsY"
      },
      "source": [
        "# ORIE 5256 Numerai Tournament"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsaJ2i7u_hsZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuxYmubM_hsZ",
        "outputId": "e35eb597-dad3-403b-b0b1-9a50512cf65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available versions:\n",
            " ['v5.0']\n",
            "Available v5.0 files:\n",
            " ['v5.0/features.json', 'v5.0/live.parquet', 'v5.0/live_benchmark_models.parquet', 'v5.0/live_example_preds.csv', 'v5.0/live_example_preds.parquet', 'v5.0/meta_model.parquet', 'v5.0/train.parquet', 'v5.0/train_benchmark_models.parquet', 'v5.0/validation.parquet', 'v5.0/validation_benchmark_models.parquet', 'v5.0/validation_example_preds.csv', 'v5.0/validation_example_preds.parquet']\n"
          ]
        }
      ],
      "source": [
        "# Initialize NumerAPI - the official Python API client for Numerai\n",
        "from numerapi import NumerAPI\n",
        "napi = NumerAPI()\n",
        "\n",
        "# list the datasets and available versions\n",
        "all_datasets = napi.list_datasets()\n",
        "dataset_versions = list(set(d.split('/')[0] for d in all_datasets))\n",
        "print(\"Available versions:\\n\", dataset_versions)\n",
        "\n",
        "# Set data version to one of the latest datasets\n",
        "DATA_VERSION = \"v5.0\"\n",
        "\n",
        "# Print all files available for download for our version\n",
        "current_version_files = [f for f in all_datasets if f.startswith(DATA_VERSION)]\n",
        "print(\"Available\", DATA_VERSION, \"files:\\n\", current_version_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dT1zts6_hsa"
      },
      "source": [
        "## 1. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMOUwOsx_hsa"
      },
      "source": [
        "We will use the `medium` feature set offer by Numerai. This feature set contains a total of 705 features. In this section, we will perform some feature engineering methods to ensure the stationarity of the data, and to reduce the dimensionality to avoid curse of dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoI7t1hE_hsa",
        "outputId": "f6ea97f7-486f-4458-e3de-16eb85b2d40a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-19 14:43:41,010 INFO numerapi.utils: target file already exists\n",
            "2024-11-19 14:43:41,012 INFO numerapi.utils: download complete\n",
            "2024-11-19 14:43:41,682 INFO numerapi.utils: target file already exists\n",
            "2024-11-19 14:43:41,683 INFO numerapi.utils: download complete\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "napi = NumerAPI()  # initialize API client\n",
        "DATA_VERSION = 'v5.0'\n",
        "\n",
        "# Load metadata\n",
        "napi.download_dataset(f'{DATA_VERSION}/features.json')\n",
        "feature_metadata = json.load(open(f'{DATA_VERSION}/features.json'))\n",
        "feature_sets = feature_metadata['feature_sets']\n",
        "medium_features = feature_sets['medium']\n",
        "\n",
        "# Load training data\n",
        "napi.download_dataset(f'{DATA_VERSION}/train.parquet')\n",
        "train_set = pd.read_parquet(f'{DATA_VERSION}/train.parquet', columns=['era', 'target'] + medium_features)\n",
        "\n",
        "# Downsample to every 4th era\n",
        "train_set = train_set[train_set['era'].isin(train_set['era'].unique()[::4])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfheJYjk_hsa",
        "outputId": "b18ba365-4a63-4a7d-d43f-af4bf5a6de7e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>era</th>\n",
              "      <th>target</th>\n",
              "      <th>feature_able_deprived_nona</th>\n",
              "      <th>feature_ablest_inflexional_egeria</th>\n",
              "      <th>feature_absorbable_hyperalgesic_mode</th>\n",
              "      <th>feature_accoutered_revolute_vexillology</th>\n",
              "      <th>feature_acetose_crackerjack_needlecraft</th>\n",
              "      <th>feature_acheulian_conserving_output</th>\n",
              "      <th>feature_acronychal_bilobate_stevenage</th>\n",
              "      <th>feature_acrylic_gallic_wine</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_working_jain_acromegaly</th>\n",
              "      <th>feature_wrapround_chrestomathic_timarau</th>\n",
              "      <th>feature_xanthic_transpadane_saleswoman</th>\n",
              "      <th>feature_xanthochroid_petrified_gutenberg</th>\n",
              "      <th>feature_zincy_cirrhotic_josh</th>\n",
              "      <th>feature_zippy_trine_diffraction</th>\n",
              "      <th>feature_zonal_snuffly_chemism</th>\n",
              "      <th>feature_zygotic_middlebrow_caribbean</th>\n",
              "      <th>feature_zymolytic_intertidal_privet</th>\n",
              "      <th>feature_zymotic_windswept_cooky</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n0007b5abb0c3a25</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003bba8a98662e4</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003bee128c2fcfc</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0048ac83aff7194</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0055a2401ba6480</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 707 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   era  target  feature_able_deprived_nona  \\\n",
              "id                                                           \n",
              "n0007b5abb0c3a25  0001    0.25                           1   \n",
              "n003bba8a98662e4  0001    0.25                           3   \n",
              "n003bee128c2fcfc  0001    0.75                           1   \n",
              "n0048ac83aff7194  0001    0.25                           1   \n",
              "n0055a2401ba6480  0001    0.25                           3   \n",
              "\n",
              "                  feature_ablest_inflexional_egeria  \\\n",
              "id                                                    \n",
              "n0007b5abb0c3a25                                  2   \n",
              "n003bba8a98662e4                                  2   \n",
              "n003bee128c2fcfc                                  2   \n",
              "n0048ac83aff7194                                  2   \n",
              "n0055a2401ba6480                                  2   \n",
              "\n",
              "                  feature_absorbable_hyperalgesic_mode  \\\n",
              "id                                                       \n",
              "n0007b5abb0c3a25                                     3   \n",
              "n003bba8a98662e4                                     4   \n",
              "n003bee128c2fcfc                                     0   \n",
              "n0048ac83aff7194                                     3   \n",
              "n0055a2401ba6480                                     3   \n",
              "\n",
              "                  feature_accoutered_revolute_vexillology  \\\n",
              "id                                                          \n",
              "n0007b5abb0c3a25                                        2   \n",
              "n003bba8a98662e4                                        1   \n",
              "n003bee128c2fcfc                                        2   \n",
              "n0048ac83aff7194                                        4   \n",
              "n0055a2401ba6480                                        4   \n",
              "\n",
              "                  feature_acetose_crackerjack_needlecraft  \\\n",
              "id                                                          \n",
              "n0007b5abb0c3a25                                        3   \n",
              "n003bba8a98662e4                                        0   \n",
              "n003bee128c2fcfc                                        4   \n",
              "n0048ac83aff7194                                        0   \n",
              "n0055a2401ba6480                                        1   \n",
              "\n",
              "                  feature_acheulian_conserving_output  \\\n",
              "id                                                      \n",
              "n0007b5abb0c3a25                                    2   \n",
              "n003bba8a98662e4                                    2   \n",
              "n003bee128c2fcfc                                    2   \n",
              "n0048ac83aff7194                                    2   \n",
              "n0055a2401ba6480                                    2   \n",
              "\n",
              "                  feature_acronychal_bilobate_stevenage  \\\n",
              "id                                                        \n",
              "n0007b5abb0c3a25                                      2   \n",
              "n003bba8a98662e4                                      3   \n",
              "n003bee128c2fcfc                                      0   \n",
              "n0048ac83aff7194                                      3   \n",
              "n0055a2401ba6480                                      4   \n",
              "\n",
              "                  feature_acrylic_gallic_wine  ...  \\\n",
              "id                                             ...   \n",
              "n0007b5abb0c3a25                            2  ...   \n",
              "n003bba8a98662e4                            2  ...   \n",
              "n003bee128c2fcfc                            2  ...   \n",
              "n0048ac83aff7194                            2  ...   \n",
              "n0055a2401ba6480                            2  ...   \n",
              "\n",
              "                  feature_working_jain_acromegaly  \\\n",
              "id                                                  \n",
              "n0007b5abb0c3a25                                2   \n",
              "n003bba8a98662e4                                2   \n",
              "n003bee128c2fcfc                                2   \n",
              "n0048ac83aff7194                                2   \n",
              "n0055a2401ba6480                                2   \n",
              "\n",
              "                  feature_wrapround_chrestomathic_timarau  \\\n",
              "id                                                          \n",
              "n0007b5abb0c3a25                                        0   \n",
              "n003bba8a98662e4                                        0   \n",
              "n003bee128c2fcfc                                        3   \n",
              "n0048ac83aff7194                                        0   \n",
              "n0055a2401ba6480                                        1   \n",
              "\n",
              "                  feature_xanthic_transpadane_saleswoman  \\\n",
              "id                                                         \n",
              "n0007b5abb0c3a25                                       3   \n",
              "n003bba8a98662e4                                       0   \n",
              "n003bee128c2fcfc                                       3   \n",
              "n0048ac83aff7194                                       2   \n",
              "n0055a2401ba6480                                       3   \n",
              "\n",
              "                  feature_xanthochroid_petrified_gutenberg  \\\n",
              "id                                                           \n",
              "n0007b5abb0c3a25                                         2   \n",
              "n003bba8a98662e4                                         2   \n",
              "n003bee128c2fcfc                                         2   \n",
              "n0048ac83aff7194                                         1   \n",
              "n0055a2401ba6480                                         3   \n",
              "\n",
              "                  feature_zincy_cirrhotic_josh  \\\n",
              "id                                               \n",
              "n0007b5abb0c3a25                             4   \n",
              "n003bba8a98662e4                             0   \n",
              "n003bee128c2fcfc                             2   \n",
              "n0048ac83aff7194                             1   \n",
              "n0055a2401ba6480                             2   \n",
              "\n",
              "                  feature_zippy_trine_diffraction  \\\n",
              "id                                                  \n",
              "n0007b5abb0c3a25                                3   \n",
              "n003bba8a98662e4                                0   \n",
              "n003bee128c2fcfc                                3   \n",
              "n0048ac83aff7194                                4   \n",
              "n0055a2401ba6480                                4   \n",
              "\n",
              "                  feature_zonal_snuffly_chemism  \\\n",
              "id                                                \n",
              "n0007b5abb0c3a25                              2   \n",
              "n003bba8a98662e4                              2   \n",
              "n003bee128c2fcfc                              2   \n",
              "n0048ac83aff7194                              2   \n",
              "n0055a2401ba6480                              2   \n",
              "\n",
              "                  feature_zygotic_middlebrow_caribbean  \\\n",
              "id                                                       \n",
              "n0007b5abb0c3a25                                     1   \n",
              "n003bba8a98662e4                                     0   \n",
              "n003bee128c2fcfc                                     2   \n",
              "n0048ac83aff7194                                     0   \n",
              "n0055a2401ba6480                                     4   \n",
              "\n",
              "                  feature_zymolytic_intertidal_privet  \\\n",
              "id                                                      \n",
              "n0007b5abb0c3a25                                    0   \n",
              "n003bba8a98662e4                                    0   \n",
              "n003bee128c2fcfc                                    2   \n",
              "n0048ac83aff7194                                    2   \n",
              "n0055a2401ba6480                                    1   \n",
              "\n",
              "                  feature_zymotic_windswept_cooky  \n",
              "id                                                 \n",
              "n0007b5abb0c3a25                                0  \n",
              "n003bba8a98662e4                                0  \n",
              "n003bee128c2fcfc                                4  \n",
              "n0048ac83aff7194                                1  \n",
              "n0055a2401ba6480                                3  \n",
              "\n",
              "[5 rows x 707 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu5D8MeX_hsa"
      },
      "source": [
        "### 1.1 Stationarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6ZxGoeC_hsa"
      },
      "outputs": [],
      "source": [
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJv_dier_hsa"
      },
      "source": [
        "### 1.2 Low Mutual Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVXyULvE_hsa"
      },
      "source": [
        "In this part, we filter out those features that are highly correlated with each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyYzuuXR_hsa"
      },
      "outputs": [],
      "source": [
        "# Calculate pairwise correlations between features. Drop one from each highly correlated pari (threshold = .8)\n",
        "\n",
        "correlation_matrix = train_set[medium_features].corr().abs()\n",
        "upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
        "train_set.drop(columns=to_drop, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeBJo70c_hsa"
      },
      "outputs": [],
      "source": [
        "train_set.to_parquet(f'train_set_low_corr.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orTb4Q6U_hsa"
      },
      "outputs": [],
      "source": [
        "# train_set = pd.read_parquet('train_set_low_corr.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylpQzCo9_hsb"
      },
      "outputs": [],
      "source": [
        "# Store ne wfeatures\n",
        "low_corr_features = list(train_set.columns[2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuP8-cjE_hsb"
      },
      "source": [
        "### 1.3 Dimension Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh0vOoAC_hsb"
      },
      "source": [
        "We will use Principal Component Analysis (PCA) to reduce the dimensionality of the data. The first 100 principal components will be kept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AczdTt1P_hsb"
      },
      "outputs": [],
      "source": [
        "# Apply PCA to the features and store the first 100 components\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100)\n",
        "# fit PCA to the features\n",
        "pca_X = pca.fit_transform(train_set[low_corr_features])\n",
        "# store the PCA features in the training set\n",
        "pca_features = [f'pca_{i}' for i in range(100)]  # name of the pca features\n",
        "df_pca_features = pd.DataFrame(pca_X, index=train_set.index, columns=pca_features)\n",
        "train_set = pd.concat([train_set, df_pca_features], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoLirJAz_hsb",
        "outputId": "880f83d1-e96e-4884-b3a8-8d50a183f4ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>era</th>\n",
              "      <th>target</th>\n",
              "      <th>pca_0</th>\n",
              "      <th>pca_1</th>\n",
              "      <th>pca_2</th>\n",
              "      <th>pca_3</th>\n",
              "      <th>pca_4</th>\n",
              "      <th>pca_5</th>\n",
              "      <th>pca_6</th>\n",
              "      <th>pca_7</th>\n",
              "      <th>...</th>\n",
              "      <th>pca_90</th>\n",
              "      <th>pca_91</th>\n",
              "      <th>pca_92</th>\n",
              "      <th>pca_93</th>\n",
              "      <th>pca_94</th>\n",
              "      <th>pca_95</th>\n",
              "      <th>pca_96</th>\n",
              "      <th>pca_97</th>\n",
              "      <th>pca_98</th>\n",
              "      <th>pca_99</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n0007b5abb0c3a25</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-5.638687</td>\n",
              "      <td>0.978715</td>\n",
              "      <td>-0.874781</td>\n",
              "      <td>2.758017</td>\n",
              "      <td>-1.400958</td>\n",
              "      <td>2.404050</td>\n",
              "      <td>4.439399</td>\n",
              "      <td>-1.285807</td>\n",
              "      <td>...</td>\n",
              "      <td>0.702926</td>\n",
              "      <td>-0.824793</td>\n",
              "      <td>-2.119851</td>\n",
              "      <td>-0.597447</td>\n",
              "      <td>-1.077121</td>\n",
              "      <td>0.225363</td>\n",
              "      <td>1.236070</td>\n",
              "      <td>-0.577384</td>\n",
              "      <td>-2.413472</td>\n",
              "      <td>0.564858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003bba8a98662e4</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-4.207500</td>\n",
              "      <td>-5.707142</td>\n",
              "      <td>-1.375227</td>\n",
              "      <td>2.484462</td>\n",
              "      <td>-3.858972</td>\n",
              "      <td>2.208746</td>\n",
              "      <td>-0.112917</td>\n",
              "      <td>-1.173767</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.165892</td>\n",
              "      <td>-0.084253</td>\n",
              "      <td>-1.588472</td>\n",
              "      <td>1.297324</td>\n",
              "      <td>1.505793</td>\n",
              "      <td>-1.381338</td>\n",
              "      <td>1.061128</td>\n",
              "      <td>1.000957</td>\n",
              "      <td>2.961764</td>\n",
              "      <td>-0.862889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n003bee128c2fcfc</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.378066</td>\n",
              "      <td>7.492630</td>\n",
              "      <td>-1.348457</td>\n",
              "      <td>2.809567</td>\n",
              "      <td>1.541221</td>\n",
              "      <td>-1.288045</td>\n",
              "      <td>0.037517</td>\n",
              "      <td>0.956088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.072736</td>\n",
              "      <td>0.068531</td>\n",
              "      <td>-0.722200</td>\n",
              "      <td>0.077919</td>\n",
              "      <td>-3.083180</td>\n",
              "      <td>0.544806</td>\n",
              "      <td>0.532066</td>\n",
              "      <td>-0.938183</td>\n",
              "      <td>0.926706</td>\n",
              "      <td>0.811019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0048ac83aff7194</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-0.027852</td>\n",
              "      <td>-7.763445</td>\n",
              "      <td>-2.374904</td>\n",
              "      <td>-2.657793</td>\n",
              "      <td>5.039552</td>\n",
              "      <td>0.549712</td>\n",
              "      <td>2.198034</td>\n",
              "      <td>2.407041</td>\n",
              "      <td>...</td>\n",
              "      <td>1.768557</td>\n",
              "      <td>0.583036</td>\n",
              "      <td>1.427570</td>\n",
              "      <td>-0.063548</td>\n",
              "      <td>-0.648705</td>\n",
              "      <td>1.912037</td>\n",
              "      <td>-0.164595</td>\n",
              "      <td>0.371036</td>\n",
              "      <td>0.134518</td>\n",
              "      <td>0.551601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0055a2401ba6480</th>\n",
              "      <td>0001</td>\n",
              "      <td>0.25</td>\n",
              "      <td>-2.958113</td>\n",
              "      <td>-3.687835</td>\n",
              "      <td>-2.035751</td>\n",
              "      <td>0.456909</td>\n",
              "      <td>3.160161</td>\n",
              "      <td>2.932720</td>\n",
              "      <td>-5.245039</td>\n",
              "      <td>3.349961</td>\n",
              "      <td>...</td>\n",
              "      <td>0.646266</td>\n",
              "      <td>-0.301437</td>\n",
              "      <td>-0.713286</td>\n",
              "      <td>-0.901061</td>\n",
              "      <td>-0.281857</td>\n",
              "      <td>0.957327</td>\n",
              "      <td>-0.442464</td>\n",
              "      <td>0.427004</td>\n",
              "      <td>0.877403</td>\n",
              "      <td>2.157457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   era  target     pca_0     pca_1     pca_2     pca_3  \\\n",
              "id                                                                       \n",
              "n0007b5abb0c3a25  0001    0.25 -5.638687  0.978715 -0.874781  2.758017   \n",
              "n003bba8a98662e4  0001    0.25 -4.207500 -5.707142 -1.375227  2.484462   \n",
              "n003bee128c2fcfc  0001    0.75  0.378066  7.492630 -1.348457  2.809567   \n",
              "n0048ac83aff7194  0001    0.25 -0.027852 -7.763445 -2.374904 -2.657793   \n",
              "n0055a2401ba6480  0001    0.25 -2.958113 -3.687835 -2.035751  0.456909   \n",
              "\n",
              "                     pca_4     pca_5     pca_6     pca_7  ...    pca_90  \\\n",
              "id                                                        ...             \n",
              "n0007b5abb0c3a25 -1.400958  2.404050  4.439399 -1.285807  ...  0.702926   \n",
              "n003bba8a98662e4 -3.858972  2.208746 -0.112917 -1.173767  ... -1.165892   \n",
              "n003bee128c2fcfc  1.541221 -1.288045  0.037517  0.956088  ...  0.072736   \n",
              "n0048ac83aff7194  5.039552  0.549712  2.198034  2.407041  ...  1.768557   \n",
              "n0055a2401ba6480  3.160161  2.932720 -5.245039  3.349961  ...  0.646266   \n",
              "\n",
              "                    pca_91    pca_92    pca_93    pca_94    pca_95    pca_96  \\\n",
              "id                                                                             \n",
              "n0007b5abb0c3a25 -0.824793 -2.119851 -0.597447 -1.077121  0.225363  1.236070   \n",
              "n003bba8a98662e4 -0.084253 -1.588472  1.297324  1.505793 -1.381338  1.061128   \n",
              "n003bee128c2fcfc  0.068531 -0.722200  0.077919 -3.083180  0.544806  0.532066   \n",
              "n0048ac83aff7194  0.583036  1.427570 -0.063548 -0.648705  1.912037 -0.164595   \n",
              "n0055a2401ba6480 -0.301437 -0.713286 -0.901061 -0.281857  0.957327 -0.442464   \n",
              "\n",
              "                    pca_97    pca_98    pca_99  \n",
              "id                                              \n",
              "n0007b5abb0c3a25 -0.577384 -2.413472  0.564858  \n",
              "n003bba8a98662e4  1.000957  2.961764 -0.862889  \n",
              "n003bee128c2fcfc -0.938183  0.926706  0.811019  \n",
              "n0048ac83aff7194  0.371036  0.134518  0.551601  \n",
              "n0055a2401ba6480  0.427004  0.877403  2.157457  \n",
              "\n",
              "[5 rows x 102 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_set.drop(columns=low_corr_features, inplace=True)\n",
        "train_set.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY32qQ2j_hsb"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRS6Z2Tv_hsb"
      },
      "source": [
        "We will use the Mean Decrease Accuracy (MDA) analysis to select the most important features. For this multi-class classification problem, our baseline classifier is Random Forest. We will use Purged K-Fold Cross Validation with AUC-ROC as scoring metric. Features with positive mean score improvement will be kept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96pBm57x_hsb"
      },
      "outputs": [],
      "source": [
        "train_set['era'] = train_set['era'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU_fttig_hsb"
      },
      "outputs": [],
      "source": [
        "# Construct inputs\n",
        "\n",
        "t1 = pd.Series((train_set['era'] + 4).values, index=train_set['era'])\n",
        "X = train_set[pca_features].copy()\n",
        "X.index = t1.index\n",
        "y = train_set['target'].copy()\n",
        "y.index = t1.index\n",
        "y = y.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ucDFLM3_hsb"
      },
      "outputs": [],
      "source": [
        "# Compute sample weights\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "sample_weight = compute_sample_weight(class_weight='balanced', y=train_set['target'])\n",
        "sample_weight = pd.Series(sample_weight, index=train_set.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uqb-g85t_hsb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection._split import _BaseKFold\n",
        "\n",
        "class PurgedKFold(_BaseKFold):\n",
        "    \"\"\"Extend KFold class to work with labels that span intervals.\n",
        "\n",
        "    The train is purged of observations overlapping test-label intervals.\n",
        "    Test set is assumed contiguous (shuffle=False), w/o training samples in between.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_splits=3, t1=None, pctEmbargo=0.0):\n",
        "        \"\"\"Initialize PurgedKFold object.\n",
        "\n",
        "        Args:\n",
        "            n_splits (int): Number of splits. Default is 3.\n",
        "            t1 (pd.Series):\n",
        "                t1.index: time when the observation started\n",
        "                t1.value: time when the observation ended\n",
        "            pctEmbargo (float): Percentage of embargo on test set. Embargo step = pctEmbargo * T. Default is 0.\n",
        "        \"\"\"\n",
        "        if not isinstance(t1, pd.Series):\n",
        "            raise ValueError('Label Through Dates must be a pd.Series')\n",
        "        super(PurgedKFold, self).__init__(\n",
        "            n_splits, shufﬂe=False, random_state=None\n",
        "        )\n",
        "\n",
        "        self.t1 = t1\n",
        "        self.pctEmbargo = pctEmbargo\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        \"\"\"Generate indices to split data into training and test set.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Features.\n",
        "            y (pd.Series): Labels.\n",
        "            groups: Ignored.\n",
        "        \"\"\"\n",
        "        if (X.index == self.t1.index).sum() != len(self.t1):\n",
        "            raise ValueError('X and ThruDateValues must have the same index')\n",
        "\n",
        "        indices = np.arange(X.shape[0])\n",
        "\n",
        "        mbrg = int(X.shape[0] * self.pctEmbargo)\n",
        "        test_starts = [\n",
        "            (i[0], i[-1] + 1)\n",
        "            for i in np.array_split(np.arange(X.shape[0]), self.n_splits)\n",
        "        ]\n",
        "        for test_start, test_end in test_starts:\n",
        "            t0 = self.t1.index[test_start]   # start of test set\n",
        "            test_indices = indices[test_start: test_end]\n",
        "\n",
        "            max_t1 = self.t1.iloc[test_indices].max()\n",
        "            maxT1Idx = self.t1.index.searchsorted(self.t1.iloc[test_indices].max())\n",
        "            train_indices = list(t1[t1 <= t0].reset_index(drop=True).index)\n",
        "            if maxT1Idx < X.shape[0]:   # right train (with embargo)\n",
        "                train_indices = np.concatenate(\n",
        "                    (train_indices, indices[maxT1Idx + mbrg :])\n",
        "                )\n",
        "            yield train_indices, test_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdDkVBTV_hsc"
      },
      "outputs": [],
      "source": [
        "def featImpMDA(\n",
        "    clf, X, y, cv, sample_weight, t1, pctEmbargo, scoring='auc-roc'\n",
        "):\n",
        "    \"\"\"feat importance based on OOS score reduction\"\"\"\n",
        "    if scoring not in ['auc-roc']:\n",
        "        raise Exception('wrong scoring method.')\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    cvGen = PurgedKFold(\n",
        "        n_splits=cv, t1=t1, pctEmbargo=pctEmbargo\n",
        "    )   # purged cv\n",
        "    scr0 = pd.Series()\n",
        "    scr1 = pd.DataFrame(columns=X.columns)\n",
        "\n",
        "    for i, (train, test) in enumerate(cvGen.split(X=X)):\n",
        "        X0, y0, w0 = X.iloc[train, :], y.iloc[train], sample_weight.iloc[train]\n",
        "        X1, y1, w1 = X.iloc[test, :], y.iloc[test], sample_weight.iloc[test]\n",
        "        fit = clf.fit(X=X0, y=y0, sample_weight=w0.values)\n",
        "        if scoring == 'auc-roc':\n",
        "            prob = fit.predict_proba(X1)\n",
        "            scr0.loc[i] = roc_auc_score(\n",
        "                y1, prob, sample_weight=w1.values, labels=clf.classes_, multi_class='ovr', average='macro'\n",
        "            )\n",
        "        else:\n",
        "            raise Exception('Only auc-roc scoring is supported')\n",
        "        for j in X.columns:\n",
        "            X1_ = X1.copy(deep=True)\n",
        "            np.random.shuffle(X1_[j].values)   # permutation of a single column\n",
        "            if scoring == 'auc-roc':\n",
        "                prob = fit.predict_proba(X1_)\n",
        "                scr1.loc[i, j] = roc_auc_score(\n",
        "                    y1, prob, sample_weight=w1.values, labels=clf.classes_, multi_class='ovr', average='macro'\n",
        "                )\n",
        "            else:\n",
        "                raise Exception('Only auc-roc scoring is supported')\n",
        "    imp = (-scr1).add(scr0, axis=0)\n",
        "    if scoring == 'auc-roc':\n",
        "        imp = imp / (1.0 - scr1)\n",
        "    else:\n",
        "        raise Exception('Only auc-roc scoring is supported')\n",
        "    imp = pd.concat(\n",
        "        {'mean': imp.mean(), 'std': imp.std() * imp.shape[0] ** -0.5}, axis=1\n",
        "    )\n",
        "    return imp, scr0.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZJrW1VE_hsc"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_features=int(1))\n",
        "imp, scr0mean = featImpMDA(\n",
        "    clf,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    cv=5,\n",
        "    sample_weight=sample_weight,\n",
        "    t1=t1,\n",
        "    pctEmbargo=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_HzE4J5_hsc",
        "outputId": "5b6a2d34-27e9-406d-8fa1-29ff1bb72e28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "83"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find features with import mean > 0\n",
        "imp_pca_features = list(imp[imp['mean'] > 0].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MglhmmM1_hsc"
      },
      "outputs": [],
      "source": [
        "train_set_selected = train_set[['era', 'target'] + imp_pca_features]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}